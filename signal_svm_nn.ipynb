{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Load training and test data, separate features (X) and target (y).\n",
        " Identify numeric columns and apply StandardScaler via ColumnTransformer\n",
        " to normalize inputs before model training.\n"
      ],
      "metadata": {
        "id": "u8utfrURBcQ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWIXq_4u6jMN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "# Load data\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "X = train.drop(columns=[\"category\"])\n",
        "y = train[\"category\"]\n",
        "\n",
        "# Preprocessing\n",
        "num_cols = [\"signal_strength\", \"response_level\"]\n",
        "cat_cols = []  # none in features, only target\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", StandardScaler(), num_cols)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a helper function 'evaluate_model' to train and test models, printing key metrics.\n",
        "Build an SVM pipeline with preprocessing and tune hyperparameters using GridSearchCV.\n",
        "Split the data into train/validation sets and evaluate the best SVM model.\n"
      ],
      "metadata": {
        "id": "v5dtnrKLBiGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_train, y_train, X_valid, y_valid, name=\"Model\"):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_valid)\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(classification_report(y_valid, y_pred))\n",
        "    print(confusion_matrix(y_valid, y_pred))\n",
        "\n",
        "\n",
        "# SVM with GridSearchCV\n",
        "\n",
        "svm_pipe = Pipeline([\n",
        "    (\"prep\", preprocessor),\n",
        "    (\"clf\", SVC(probability=True))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    \"clf__kernel\": [\"linear\", \"rbf\"],\n",
        "    \"clf__C\": [0.1, 1, 10],\n",
        "    \"clf__gamma\": [\"scale\", \"auto\"]\n",
        "}\n",
        "\n",
        "svm_cv = GridSearchCV(\n",
        "    svm_pipe,\n",
        "    param_grid,\n",
        "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "svm_cv.fit(X_train, y_train)\n",
        "print(\"Best params:\", svm_cv.best_params_)\n",
        "best_svm = svm_cv.best_estimator_\n",
        "evaluate_model(best_svm, X_train, y_train, X_valid, y_valid, \"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSCVBRSk9GNS",
        "outputId": "36d16031-0639-463a-8fe4-a712323181f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'clf__C': 1, 'clf__gamma': 'scale', 'clf__kernel': 'rbf'}\n",
            "\n",
            "=== SVM ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Group_A       0.94      0.98      0.96        51\n",
            "     Group_B       1.00      0.99      0.99       142\n",
            "     Group_C       0.99      0.99      0.99        96\n",
            "\n",
            "    accuracy                           0.99       289\n",
            "   macro avg       0.98      0.99      0.98       289\n",
            "weighted avg       0.99      0.99      0.99       289\n",
            "\n",
            "[[ 50   0   1]\n",
            " [  2 140   0]\n",
            " [  1   0  95]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a custom PyTorch-based MLP classifier:\n",
        " - __init__ sets model hyperparameters (hidden size, layers, dropout, lr, etc.).\n",
        "- _build_model builds a feedforward network with ReLU and Dropout.\n",
        "- fit trains the model using Adam optimizer and CrossEntropyLoss on one-hot encoded labels.\n",
        "- predict returns class indices from the trained network.\n",
        "- score computes accuracy by comparing predictions with true labels.\n"
      ],
      "metadata": {
        "id": "nH0D68GrBz5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "\n",
        "class TorchMLPClassifier:\n",
        "    def __init__(self, hidden_dim=64, hidden_layers=2, dropout=0.2, lr=1e-3, batch_size=64, epochs=20):\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.dropout = dropout\n",
        "        self.lr = lr\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def _build_model(self, input_dim, output_dim):\n",
        "        layers = []\n",
        "        in_dim = input_dim\n",
        "        for _ in range(self.hidden_layers):\n",
        "            layers += [nn.Linear(in_dim, self.hidden_dim), nn.ReLU(), nn.Dropout(self.dropout)]\n",
        "            in_dim = self.hidden_dim\n",
        "        layers += [nn.Linear(in_dim, output_dim)]\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.asarray(X, dtype=np.float32)\n",
        "        y = pd.get_dummies(y).values.astype(np.float32)  # one-hot\n",
        "        dataset = TensorDataset(torch.from_numpy(X), torch.from_numpy(y))\n",
        "        loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        input_dim = X.shape[1]\n",
        "        output_dim = y.shape[1]\n",
        "        self.model = self._build_model(input_dim, output_dim)\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            for xb, yb in loader:\n",
        "                optimizer.zero_grad()\n",
        "                logits = self.model(xb)\n",
        "                loss = criterion(logits, torch.argmax(yb, dim=1))\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.asarray(X, dtype=np.float32)\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(torch.from_numpy(X))\n",
        "            preds = torch.argmax(logits, dim=1).numpy()\n",
        "        return preds\n",
        "\n",
        "    def score(self, X, y):\n",
        "        preds = self.predict(X)\n",
        "        return (preds == pd.Categorical(y).codes).mean()"
      ],
      "metadata": {
        "id": "OVHKyr1R9g1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wrap the custom PyTorch MLP inside a scikit-learn compatible class (TorchWrapper).\n",
        "LabelEncoder ensures string labels are converted to integers for training and back to strings for predictions.\n",
        "Build a pipeline with preprocessing + TorchWrapper, then tune hyperparameters using GridSearchCV.\n",
        "Finally, evaluate the best PyTorch MLP model on the validation set.\n"
      ],
      "metadata": {
        "id": "duGYbzHkCE0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "class TorchWrapper(BaseEstimator):\n",
        "    def __init__(self, hidden_dim=64, hidden_layers=2, dropout=0.2,\n",
        "                 lr=1e-3, batch_size=64, epochs=20):\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.dropout = dropout\n",
        "        self.lr = lr\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.clf = TorchMLPClassifier(hidden_dim, hidden_layers,\n",
        "                                      dropout, lr, batch_size, epochs)\n",
        "        self.le_ = None  # label encoder\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Encode string labels to integers\n",
        "        self.le_ = LabelEncoder()\n",
        "        y_enc = self.le_.fit_transform(y)\n",
        "        self.clf.fit(X, y_enc)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        preds = self.clf.predict(X)\n",
        "        # Map back to original string labels\n",
        "        return self.le_.inverse_transform(preds)\n",
        "\n",
        "    def score(self, X, y):\n",
        "        y_enc = self.le_.transform(y)\n",
        "        preds = self.clf.predict(X)\n",
        "        return (preds == y_enc).mean()\n",
        "\n",
        "torch_pipe = Pipeline([\n",
        "    (\"prep\", preprocessor),\n",
        "    (\"clf\", TorchWrapper())\n",
        "])\n",
        "\n",
        "torch_param_grid = {\n",
        "    \"clf__hidden_dim\": [64, 128],\n",
        "    \"clf__hidden_layers\": [1, 2],\n",
        "    \"clf__dropout\": [0.1, 0.3],\n",
        "    \"clf__lr\": [1e-3, 3e-4],\n",
        "    \"clf__epochs\": [20, 40]\n",
        "}\n",
        "\n",
        "torch_cv = GridSearchCV(\n",
        "    torch_pipe,\n",
        "    param_grid=torch_param_grid,\n",
        "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=1\n",
        ")\n",
        "\n",
        "torch_cv.fit(X_train, y_train)\n",
        "print(\"Best params:\", torch_cv.best_params_)\n",
        "best_svm = torch_cv.best_estimator_\n",
        "\n",
        "# Now evaluation works with string labels consistently\n",
        "evaluate_model(torch_cv, X_train, y_train, X_valid, y_valid, \"PyTorch MLP\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKv0HhqC93oz",
        "outputId": "e0a992b5-8793-4282-9bfe-9895f2602af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'clf__dropout': 0.3, 'clf__epochs': 20, 'clf__hidden_dim': 64, 'clf__hidden_layers': 2, 'clf__lr': 0.0003}\n",
            "\n",
            "=== PyTorch MLP ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Group_A       0.88      0.90      0.89        51\n",
            "     Group_B       0.99      0.96      0.98       142\n",
            "     Group_C       0.96      0.99      0.97        96\n",
            "\n",
            "    accuracy                           0.96       289\n",
            "   macro avg       0.95      0.95      0.95       289\n",
            "weighted avg       0.96      0.96      0.96       289\n",
            "\n",
            "[[ 46   1   4]\n",
            " [  5 137   0]\n",
            " [  1   0  95]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Htr5_r92R1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lu5CJRUV2R_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f_brvQhR2SD9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}